# 8. Architecture systÃ¨me et interaction CPUâ€“GPU  
*(System Architecture and CPUâ€“GPU Interaction)*  

## ğŸ“˜ Sommaire local / Local Table of Contents  
1. [8.1 Interconnexion et communication / Interconnects and Communication](#81-interconnexion-et-communication--interconnects-and-communication)  
2. [8.2 MÃ©moire partagÃ©e et unifiÃ©e / Shared and Unified Memory](#82-mÃ©moire-partagÃ©e-et-unifiÃ©e--shared-and-unified-memory)  
3. [8.3 Synchronisation et cohÃ©rence / Synchronization and Coherency](#83-synchronisation-et-cohÃ©rence--synchronization-and-coherency)  
4. [8.4 Gestion des ressources et scheduling / Resource Management and Scheduling](#84-gestion-des-ressources-et-scheduling--resource-management-and-scheduling)  
5. [8.5 Virtualisation et systÃ¨mes hÃ©tÃ©rogÃ¨nes / Virtualization and Heterogeneous Systems](#85-virtualisation-et-systÃ¨mes-hÃ©tÃ©rogÃ¨nes--virtualization-and-heterogeneous-systems)  

---

## 8.1 Interconnexion et communication / Interconnects and Communication  

8.1.1 â€“ Quâ€™est-ce quâ€™un bus dâ€™interconnexion ?  
8.1.2 â€“ Quelle est la diffÃ©rence entre bus parallÃ¨le et sÃ©rie ?  
8.1.3 â€“ Quâ€™est-ce que le bus PCI Express ?  
8.1.4 â€“ Quelle est la diffÃ©rence entre PCIe 3.0, 4.0, 5.0, 6.0 ?  
8.1.5 â€“ Quâ€™est-ce que la bande passante dâ€™un lien PCIe x16 ?  
8.1.6 â€“ Quâ€™est-ce que la latence dâ€™un transfert PCIe ?  
8.1.7 â€“ Quâ€™est-ce que NVLink ?  
8.1.8 â€“ Quelle est la diffÃ©rence entre NVLink et PCIe ?  
8.1.9 â€“ Quâ€™est-ce que Infinity Fabric (AMD) ?  
8.1.10 â€“ Quâ€™est-ce que CXL (Compute Express Link) ?  
8.1.11 â€“ Quelle est la diffÃ©rence entre CXL et PCIe ?  
8.1.12 â€“ Quâ€™est-ce quâ€™une topologie NUMA multi-socket ?  
8.1.13 â€“ Quâ€™est-ce quâ€™un pont PCIe (bridge) ?  
8.1.14 â€“ Quelle est la diffÃ©rence entre liaison point-Ã -point et bus partagÃ© ?  
8.1.15 â€“ Quâ€™est-ce quâ€™une architecture en anneau (ring bus) ?  
8.1.16 â€“ Quâ€™est-ce quâ€™une architecture mesh ?  
8.1.17 â€“ Quelle est la diffÃ©rence entre communication synchrone et asynchrone ?  
8.1.18 â€“ Quâ€™est-ce quâ€™un â€œcommand bufferâ€ dans la communication CPU-GPU ?  
8.1.19 â€“ Quâ€™est-ce quâ€™un DMA (Direct Memory Access) ?  
8.1.20 â€“ Quelle est la diffÃ©rence entre DMA bloquant et non bloquant ?  

---

## 8.2 MÃ©moire partagÃ©e et unifiÃ©e / Shared and Unified Memory  

8.2.1 â€“ Quâ€™est-ce quâ€™une mÃ©moire unifiÃ©e CPU-GPU ?  
8.2.2 â€“ Quelle est la diffÃ©rence entre mÃ©moire unifiÃ©e et mÃ©moire partagÃ©e ?  
8.2.3 â€“ Quâ€™est-ce que la gestion de page unifiÃ©e (UPM) ?  
8.2.4 â€“ Quelle est la diffÃ©rence entre accÃ¨s unifiÃ© et copie explicite ?  
8.2.5 â€“ Quâ€™est-ce que la cohÃ©rence mÃ©moire CPU-GPU ?  
8.2.6 â€“ Quâ€™est-ce quâ€™un â€œpinned memory bufferâ€ ?  
8.2.7 â€“ Quelle est la diffÃ©rence entre pageable et pinned memory ?  
8.2.8 â€“ Quâ€™est-ce quâ€™un transfert zÃ©ro-copie ?  
8.2.9 â€“ Quâ€™est-ce que le â€œpeer-to-peer memory accessâ€ ?  
8.2.10 â€“ Quâ€™est-ce quâ€™un â€œBARâ€ (Base Address Register) PCIe ?  
8.2.11 â€“ Quâ€™est-ce que la mÃ©moire HBM unifiÃ©e ?  
8.2.12 â€“ Quelle est la diffÃ©rence entre HBM et GDDR ?  
8.2.13 â€“ Quâ€™est-ce quâ€™un GPU NUMA-aware ?  
8.2.14 â€“ Quâ€™est-ce que la cohÃ©rence via NVLink ?  
8.2.15 â€“ Quâ€™est-ce que le â€œUnified Virtual Addressingâ€ (UVA) ?  
8.2.16 â€“ Quâ€™est-ce quâ€™un mapping mÃ©moire partagÃ© entre processus ?  
8.2.17 â€“ Quelle est la diffÃ©rence entre mÃ©moire virtuelle et physique sur GPU ?  
8.2.18 â€“ Quâ€™est-ce que la pagination de mÃ©moire GPU ?  
8.2.19 â€“ Quâ€™est-ce que la compression mÃ©moire Ã  la volÃ©e ?  
8.2.20 â€“ Quelle est la diffÃ©rence entre VRAM partagÃ©e et dÃ©diÃ©e ?  

---

## 8.3 Synchronisation et cohÃ©rence / Synchronization and Coherency  

8.3.1 â€“ Quâ€™est-ce quâ€™une barriÃ¨re de synchronisation CPU-GPU ?  
8.3.2 â€“ Quelle est la diffÃ©rence entre fence et semaphore ?  
8.3.3 â€“ Quâ€™est-ce quâ€™un fence Vulkan ou DirectX12 ?  
8.3.4 â€“ Quâ€™est-ce quâ€™un event GPU ?  
8.3.5 â€“ Quelle est la diffÃ©rence entre synchronisation logicielle et matÃ©rielle ?  
8.3.6 â€“ Quâ€™est-ce quâ€™une latence de synchronisation ?  
8.3.7 â€“ Quelle est la diffÃ©rence entre pipeline stall et sync stall ?  
8.3.8 â€“ Quâ€™est-ce que la â€œcommand queue dependencyâ€ ?  
8.3.9 â€“ Quâ€™est-ce quâ€™une timeline semaphore ?  
8.3.10 â€“ Quelle est la diffÃ©rence entre â€œwaitâ€ et â€œsignalâ€ ?  
8.3.11 â€“ Quâ€™est-ce quâ€™une barriÃ¨re mÃ©moire ?  
8.3.12 â€“ Quâ€™est-ce quâ€™un â€œflushâ€ mÃ©moire GPU ?  
8.3.13 â€“ Quâ€™est-ce que la cohÃ©rence cache entre CPU et GPU ?  
8.3.14 â€“ Quelle est la diffÃ©rence entre cohÃ©rence forte et faible ?  
8.3.15 â€“ Quâ€™est-ce que la â€œcoherency domainâ€ ?  
8.3.16 â€“ Quâ€™est-ce que la synchronisation inter-GPU ?  
8.3.17 â€“ Quelle est la diffÃ©rence entre multi-GPU synchrone et asynchrone ?  
8.3.18 â€“ Quâ€™est-ce que la latence de synchronisation multi-device ?  
8.3.19 â€“ Quâ€™est-ce quâ€™un â€œbarrier scopeâ€ ?  
8.3.20 â€“ Quâ€™est-ce que la cohÃ©rence en mÃ©moire partagÃ©e CUDA ?  

---

## 8.4 Gestion des ressources et scheduling / Resource Management and Scheduling  

8.4.1 â€“ Quâ€™est-ce quâ€™un scheduler CPU-GPU ?  
8.4.2 â€“ Quelle est la diffÃ©rence entre ordonnanceur matÃ©riel et logiciel ?  
8.4.3 â€“ Quâ€™est-ce quâ€™un job de calcul GPU ?  
8.4.4 â€“ Quelle est la diffÃ©rence entre job compute et job graphique ?  
8.4.5 â€“ Quâ€™est-ce quâ€™une â€œcommand submissionâ€ ?  
8.4.6 â€“ Quâ€™est-ce quâ€™une â€œrender queueâ€ ?  
8.4.7 â€“ Quâ€™est-ce quâ€™un â€œframe graph schedulerâ€ ?  
8.4.8 â€“ Quelle est la diffÃ©rence entre prioritÃ© CPU et GPU ?  
8.4.9 â€“ Quâ€™est-ce quâ€™un â€œcontext switchâ€ GPU ?  
8.4.10 â€“ Quâ€™est-ce quâ€™un GPU context preemption ?  
8.4.11 â€“ Quelle est la diffÃ©rence entre scheduling coopÃ©ratif et prÃ©emptif ?  
8.4.12 â€“ Quâ€™est-ce que la gestion de charge GPU (load balancing) ?  
8.4.13 â€“ Quâ€™est-ce que la latence de soumission (submission latency) ?  
8.4.14 â€“ Quâ€™est-ce quâ€™un pipeline de commandes asynchrones ?  
8.4.15 â€“ Quâ€™est-ce quâ€™un timeline scheduling ?  
8.4.16 â€“ Quelle est la diffÃ©rence entre travail batchÃ© et interactif ?  
8.4.17 â€“ Quâ€™est-ce que la gestion dynamique de frÃ©quence (DVFS) ?  
8.4.18 â€“ Quâ€™est-ce quâ€™une gestion dâ€™Ã©nergie adaptative GPU ?  
8.4.19 â€“ Quâ€™est-ce quâ€™une â€œwork stealing queueâ€ ?  
8.4.20 â€“ Quâ€™est-ce que la latence de dispatch CPU-GPU ?  

---

## 8.5 Virtualisation et systÃ¨mes hÃ©tÃ©rogÃ¨nes / Virtualization and Heterogeneous Systems  

8.5.1 â€“ Quâ€™est-ce que la virtualisation GPU ?  
8.5.2 â€“ Quelle est la diffÃ©rence entre SR-IOV et MxGPU ?  
8.5.3 â€“ Quâ€™est-ce quâ€™un vGPU ?  
8.5.4 â€“ Quâ€™est-ce quâ€™une virtualisation complÃ¨te vs partielle ?  
8.5.5 â€“ Quelle est la diffÃ©rence entre â€œpassthroughâ€ et â€œparavirtualisationâ€ ?  
8.5.6 â€“ Quâ€™est-ce que la partition logique GPU ?  
8.5.7 â€“ Quâ€™est-ce quâ€™un â€œmulti-instance GPUâ€ (MIG NVIDIA) ?  
8.5.8 â€“ Quâ€™est-ce que la virtualisation CPU-GPU unifiÃ©e ?  
8.5.9 â€“ Quâ€™est-ce quâ€™un OS hÃ©tÃ©rogÃ¨ne (HSA) ?  
8.5.10 â€“ Quâ€™est-ce que le modÃ¨le HSA de mÃ©moire unifiÃ©e ?  
8.5.11 â€“ Quâ€™est-ce que la gestion du contexte multi-tenant ?  
8.5.12 â€“ Quelle est la diffÃ©rence entre contexte virtuel et physique ?  
8.5.13 â€“ Quâ€™est-ce quâ€™un hyperviseur GPU ?  
8.5.14 â€“ Quâ€™est-ce que la migration de contexte GPU ?  
8.5.15 â€“ Quâ€™est-ce que la compatibilitÃ© binaire ISA GPU ?  
8.5.16 â€“ Quâ€™est-ce que la virtualisation de commande graphique ?  
8.5.17 â€“ Quâ€™est-ce quâ€™un â€œresource isolation domainâ€ ?  
8.5.18 â€“ Quâ€™est-ce que la supervision CPU dâ€™un GPU partagÃ© ?  
8.5.19 â€“ Quelle est la diffÃ©rence entre GPU cloud et bare-metal ?  
8.5.20 â€“ Quâ€™est-ce que la virtualisation Ã  granularitÃ© fine (fine-grained virtualization) ?  
